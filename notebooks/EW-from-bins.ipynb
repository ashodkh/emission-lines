{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eeae0c6-7960-45c3-bd66-2c98f705678e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/a/ashodkh/.conda/envs/myenv/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pylab as plt\n",
    "from scipy import stats, signal\n",
    "from sklearn.neighbors import KDTree\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from os import listdir\n",
    "import scipy\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from LLR import LLR\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "plt.rcParams['figure.figsize'] = [25, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fade9c2-c730-4486-8995-7e5e0d9d1bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_and_outcomes(x_in, y_in, n_out, ivar):\n",
    "    magnitudes = np.zeros([n_out,x_in.shape[1]])\n",
    "    EWs = np.zeros([n_out,len(lines)])\n",
    "    \n",
    "    select_fluxes = x_in[:,0]>0\n",
    "    for i in range(1, x_in.shape[1]):\n",
    "        select_fluxes = select_fluxes*(x_in[:,i]>0)\n",
    "    \n",
    "    x_in = x_in[select_fluxes,:]\n",
    "    y_in = y_in[select_fluxes]\n",
    "    ivar = ivar[select_fluxes]\n",
    "    \n",
    "    for i in range(n_out):\n",
    "        magnitudes[i,:] = -2.5*np.log10(x_in[i,:])\n",
    "        for j in range(len(lines)):\n",
    "            EWs[i,j] = y_in[i][j]\n",
    "    \n",
    "    ones = np.ones([n_out,1])\n",
    "    scalar = StandardScaler()\n",
    "    x_out = np.zeros([n_out,x_in.shape[1]-1])\n",
    "    for j in range(x_in.shape[1]-1):\n",
    "        x_out[:,j] = magnitudes[:,j] - magnitudes[:,j+1]\n",
    "    x_out = scalar.fit_transform(x_out)\n",
    "    \n",
    "    if (m == 0 or m == 5) or (m == 6 or m == 7):\n",
    "        x_out = np.concatenate((ones,x_out), axis=1)\n",
    "        \n",
    "    if loga:\n",
    "        y_out = np.log10(EWs[:,l])\n",
    "    else:\n",
    "        y_out = EWs[:,l]\n",
    "        \n",
    "    return x_out, y_out, ivar\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35d5a3e3-bfe5-40b5-87f0-2451fc6b61dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "HALPHA_EW\n",
      "[0.8239675708710646, 0.8555385526783092, 0.8258609872179065, 0.7971838055003495, 0.8433848616573666, 0.8076193495129861, 0.8278853048521575, 0.8376198729781957, 0.8350893637466537, 0.845338375629018]\n",
      "spearman_average= 0.8299488044644008\n",
      "[0.27616096731961165, 0.2915424976341893, 0.28499469911660325, 0.3148310685551887, 0.28103630270653485, 0.3252640448439384, 0.30119539904259135, 0.31387914090594715, 0.2935715990286196, 0.3098011520767034]\n",
      "nmad_average= 0.29922768712299275\n",
      "\n",
      "\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "HALPHA_EW\n",
      "[0.8610964232367259, 0.8878549866001573, 0.8763679483559038, 0.856240342677142, 0.8937045105219341, 0.8601805271977654, 0.8589338909795304, 0.8902040081753281, 0.8942228549940466, 0.8996695896474114]\n",
      "spearman_average= 0.8778475082385946\n",
      "[0.2639974233741571, 0.2477331137968838, 0.25123689902737395, 0.25944016249558816, 0.23437524140311414, 0.2847293554748391, 0.28305302264757276, 0.26381082513697807, 0.22665009439384154, 0.25190362729916543]\n",
      "nmad_average= 0.2566929765049514\n",
      "\n",
      "\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "HALPHA_EW\n",
      "[0.862223184199339, 0.8905679536839419, 0.8776698613167321, 0.8535368852744993, 0.8958555723241403, 0.8577215130072721, 0.8455263141867774, 0.8931458382703564, 0.898511927227536, 0.8991897779351103]\n",
      "spearman_average= 0.8773948827425706\n",
      "[0.26365973418430805, 0.25023384667251936, 0.24319387743246976, 0.27180944375140387, 0.24129782266059221, 0.2875292546770449, 0.2872993902946057, 0.26063862682857386, 0.22875379766925866, 0.24521820817979148]\n",
      "nmad_average= 0.2579634002350568\n",
      "\n",
      "\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "HALPHA_EW\n",
      "[0.8627667489796027, 0.8853084035386586, 0.8807103366182109, 0.8574468404806221, 0.8966991122222371, 0.8683563564740379, 0.8433603625979151, 0.8995095804119366, 0.9011989523101495, 0.9082158340508274]\n",
      "spearman_average= 0.8803572527684198\n",
      "[0.26330579484572886, 0.24853089010443008, 0.2533479055827693, 0.26969481989072325, 0.23593294650771965, 0.278145491219525, 0.2842636061159826, 0.24424878725623608, 0.22201455006295923, 0.23873703346648384]\n",
      "nmad_average= 0.2538221825052558\n",
      "\n",
      "\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "HALPHA_EW\n",
      "[0.8591617902872076, 0.8909582890941838, 0.8831601390045466, 0.8609128695734035, 0.898773524712674, 0.8744365801926632, 0.8515382886938493, 0.9003284575290089, 0.9052425930844057, 0.910973296888188]\n",
      "spearman_average= 0.8835485829060131\n",
      "[0.2614753068398348, 0.2520521295085211, 0.24086144843980725, 0.2658991023371729, 0.2305138095933948, 0.25978218862582514, 0.27109719997812093, 0.23926396933817387, 0.21835469738728586, 0.23340741347331076]\n",
      "nmad_average= 0.24727072655214472\n",
      "\n",
      "\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "HALPHA_EW\n",
      "[0.8458646490837697, 0.8838930078457571, 0.874791190270382, 0.8500930779332685, 0.8995246181397731, 0.8651059644730597, 0.8416935201689073, 0.8953808774041273, 0.8968301289314782, 0.9068045116832725]\n",
      "spearman_average= 0.8759981545933796\n",
      "[0.2618006725746225, 0.24091497116948463, 0.2493858881851206, 0.25811667309514524, 0.2239948135575217, 0.2628811457175647, 0.25283971832819707, 0.23824025603383892, 0.21776774740421603, 0.22165252190755796]\n",
      "nmad_average= 0.24275944079732695\n",
      "\n",
      "\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "HALPHA_EW\n",
      "[0.8501101506786374, 0.8814745309983892, 0.8665206510230539, 0.8415396130139812, 0.8912795938146678, 0.8592081492708754, 0.8365668503413951, 0.8908939910459586, 0.8910450389910075, 0.908571229203076]\n",
      "spearman_average= 0.8717209798381044\n",
      "[0.26021692823305204, 0.24306883127375223, 0.24701763809581967, 0.271937883072268, 0.23314962857329427, 0.25718910977220755, 0.2618590607787367, 0.2370004221307894, 0.21331905205123805, 0.21964026671792494]\n",
      "nmad_average= 0.24443988206990835\n",
      "\n",
      "\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "HALPHA_EW\n",
      "[0.8287552988810809, 0.8679098050559402, 0.8595259861025534, 0.8355282332304541, 0.8773974404548459, 0.849288062904787, 0.8305888825802932, 0.8821781912558427, 0.8836002216060251, 0.8926756022975166]\n",
      "spearman_average= 0.860744772436934\n",
      "[0.26730126313003444, 0.2516227299643435, 0.24684077457663925, 0.28459972330294386, 0.24247222153592213, 0.2622026926325179, 0.2800194020007443, 0.2439584350645352, 0.22737602957136677, 0.2258024858464525]\n",
      "nmad_average= 0.25321957576255005\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "server = 1 # 0 is perlmutter, 1 is cori\n",
    "server_paths = ['/pscratch/sd/a/ashodkh/', '/global/cscratch1/sd/ashodkh/']\n",
    "\n",
    "## reading fluxes and equivalent widths\n",
    "lines = [\"OII_DOUBLET_EW\",\"HGAMMA_EW\",\"HBETA_EW\",\"OIII_4959_EW\",\"OIII_5007_EW\",\"NII_6548_EW\"\\\n",
    "         ,\"HALPHA_EW\",\"NII_6584_EW\",\"SII_6716_EW\",\"SII_6731_EW\"]\n",
    "l = 6\n",
    "\n",
    "run = 0\n",
    "m = 7\n",
    "loga = True\n",
    "\n",
    "data = 0 # 0 is raw_masked, 1 is raw_unmasked, 2 is fastspec, 3 is fastphot\n",
    "data_file_names = ['raw_masked', 'raw_unmasked', 'fastspec', 'fastphot']\n",
    "data_flux_names = ['fluxes', 'fluxes', 'fluxes_fastspec', 'fluxes_fastphot']\n",
    "\n",
    "Ns = [6, 11, 16, 21, 26, 31, 41, 51]\n",
    "decades = 3 ## number of 10k galaxy files I want to load and combine\n",
    "for N in Ns:\n",
    "    n = 10*10**3\n",
    "    fluxes_bin = np.zeros([25*10**3, N-1]) ## fluxes are separated into groups of 10k galaxies\n",
    "    for i in range(decades):\n",
    "        if i == 2:\n",
    "            n = 5*10**3\n",
    "            fluxes_bin[10**4*i:25*10**3,:] =  np.load(server_paths[server] + \"fluxes_from_spectra/\" + data_file_names[data] + \"/\" + data_flux_names[data]\\\n",
    "                                                +str(i)+ \"_selection\"+str(run)+\"_\"+str(lines[l])+\"_bins\"+str(N)+\".txt.npz\")[\"arr_0\"]\n",
    "        else:\n",
    "            fluxes_bin[10**4*i:n*(i+1),:] = np.load(server_paths[server] + \"fluxes_from_spectra/\" + data_file_names[data] + \"/\" + data_flux_names[data]\\\n",
    "                                            +str(i)+ \"_selection\"+str(run)+\"_\"+str(lines[l])+\"_bins\"+str(N)+\".txt.npz\")[\"arr_0\"]\n",
    "\n",
    "        zs = np.load(\"/global/cscratch1/sd/ashodkh/target_selection/zs_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt.npz\")[\"arr_0\"][:decades*10*10**3]\n",
    "        target_lines = np.load(\"/global/cscratch1/sd/ashodkh/target_selection/line_ews_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt.npz\")[\"arr_0\"][:decades*10*10**3]\n",
    "        line_ivars = np.load(\"/global/cscratch1/sd/ashodkh/target_selection/line_ivars_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt.npz\")[\"arr_0\"][:decades*10*10**3]\n",
    "\n",
    "    x, EW, line_ivars = features_and_outcomes(fluxes_bin, target_lines, 23*10**3,line_ivars) \n",
    "    \n",
    "    N_cv = 10\n",
    "    x_split = np.split(x,N_cv)\n",
    "    EW_split = np.split(EW,N_cv)\n",
    "\n",
    "    EW_fit_all = []\n",
    "    EW_obs_all = []\n",
    "\n",
    "    spearman_all = []\n",
    "    rms_all = []\n",
    "    nmad_all = []\n",
    "    nmad2_all = []\n",
    "    for i in range(N_cv):\n",
    "        ## assigning the training and validation sets\n",
    "        x_valid = x_split[i]\n",
    "        EW_valid = EW_split[i]\n",
    "\n",
    "        x_to_combine = []\n",
    "        EW_to_combine = []\n",
    "        for j in range(N_cv):\n",
    "            if j != i:\n",
    "                x_to_combine.append(x_split[j])\n",
    "                EW_to_combine.append(EW_split[j])\n",
    "        x_train=np.concatenate(tuple(x_to_combine),axis=0)\n",
    "        EW_train=np.concatenate(tuple(EW_to_combine),axis=0)\n",
    "\n",
    "        # predicting EWs using different models\n",
    "        if m == 0:\n",
    "            EW_fit,zeros = LLR.LLR(x_valid, x_train, EW_train, 100, 'inverse_distance')\n",
    "        if m == 1:\n",
    "            model = RandomForestRegressor(n_estimators=200)\n",
    "            model.fit(x_train, EW_train)\n",
    "            EW_fit = model.predict(x_valid)\n",
    "        if m == 2:\n",
    "            model = GradientBoostingRegressor(n_estimators=100)\n",
    "            model.fit(x_train, EW_train)\n",
    "            EW_fit = model.predict(x_valid)\n",
    "        if m == 3:\n",
    "            model = xgb.XGBRegressor(n_estimators=1000, learning_rate=0.05)\n",
    "            model.fit(x_train, EW_train, early_stopping_rounds=5, eval_set=[(x_valid,EW_valid)], verbose=False)\n",
    "            EW_fit = model.predict(x_valid)\n",
    "            print(model.best_ntree_limit)\n",
    "        if m == 4:\n",
    "            model_input = layers.Input(shape=x.shape[1])\n",
    "            h1 = layers.Dense(units=100, kernel_initializer=\"he_normal\")(model_input)\n",
    "            a1 = layers.PReLU()(h1)\n",
    "            h2 = layers.Dense(units=100, kernel_initializer=\"he_normal\")(a1)\n",
    "            a2 = layers.PReLU()(h2)\n",
    "            h3 = layers.Dense(units=100, kernel_initializer=\"he_normal\")(a2)\n",
    "            a3 = layers.PReLU()(h3)\n",
    "            output_layer = layers.Dense(1, activation='linear')(a3)\n",
    "            model = keras.models.Model(inputs=model_input, outputs=output_layer)\n",
    "\n",
    "            model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3), loss='mse', metrics='mse')\n",
    "\n",
    "            n_epochs = 100\n",
    "            batch_size = 100\n",
    "            history = model.fit(x_train, EW_train, batch_size=batch_size, epochs=n_epochs, verbose=0, validation_data=(x_valid, EW_valid))\n",
    "            EW_fit = model.predict(x_valid)\n",
    "        if m == 5:\n",
    "            EW_fit,zeros = LLR.LLR(x_valid, x_train, EW_train, 200, 'inverse_distance')\n",
    "        if m == 6:\n",
    "            EW_fit,zeros = LLR.LLR(x_valid, x_train, EW_train, 800, 'inverse_distance')\n",
    "        if m == 7:\n",
    "            EW_fit,zeros = LLR.LLR(x_valid, x_train, EW_train, 1000, 'inverse_distance')\n",
    "            \n",
    "        # calculating spearman coefficient and nmad for fit. nmad2 has the error in it.\n",
    "        nmad = np.abs(EW_fit-EW_valid)\n",
    "        nmad2 = np.abs(EW_fit-EW_valid)\n",
    "\n",
    "        EW_fit_all.append(EW_fit)\n",
    "        EW_obs_all.append(EW_valid)\n",
    "\n",
    "        spearman_all.append(stats.spearmanr(EW_fit,EW_valid)[0])\n",
    "        rms_all.append(np.sqrt(mean_squared_error(EW_fit,EW_valid)))\n",
    "        nmad_all.append(1.48*np.median(nmad))\n",
    "        nmad2_all.append(1.48*np.median(nmad2))\n",
    "\n",
    "    print(lines[l])\n",
    "    print(spearman_all)\n",
    "    print('spearman_average= '+str(np.average(spearman_all)))\n",
    "    # print(rms_all)\n",
    "    # print(np.average(rms_all))\n",
    "    print(nmad_all)\n",
    "    print('nmad_average= '+str(np.average(nmad_all)))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    if loga:\n",
    "        np.savez_compressed(server_paths[server] + \"ew_results/\" + data_file_names[data] + \"/m\" + str(m) + \"/logEW_fit_\" + data_file_names[data] + \"_selection\" + str(run) + \\\n",
    "                            \"_line\" + str(lines[l]) + \"_bins\" + str(N) + \"_ML\" + str(m) + \".txt\", EW_fit_all)\n",
    "        np.savez_compressed(server_paths[server] + \"ew_results/\" + data_file_names[data] + \"/m\" + str(m) + \"/logEW_obs_\" + data_file_names[data] + \"_selection\" + str(run) + \\\n",
    "                            \"_line\" + str(lines[l]) + \"_bins\" + str(N) + \"_ML\" + str(m) + \".txt\", EW_obs_all)\n",
    "        np.savez_compressed(server_paths[server] + \"ew_results/\" + data_file_names[data] + \"/m\" + str(m) + \"/line_ivars_\" + data_file_names[data] + \"_selection\" + str(run) + \\\n",
    "                            \"_line\" + str(lines[l]) + \"_bins\" + str(N) + \"_ML\" + str(m) + \".txt\", line_ivars)\n",
    "    else:\n",
    "        np.savez_compressed(server_paths[server] + \"ew_results/\" + data_file_names[data] + \"/m\" + str(m) + \"/EW_fit_\" + data_file_names[data] + \"_selection\" + str(run) + \\\n",
    "                            \"_line\" + str(lines[l]) + \"_bins\" + str(N) + \"_ML\" + str(m) + \".txt\", EW_fit_all)\n",
    "        np.savez_compressed(server_paths[server] + \"ew_results/\" + data_file_names[data] + \"/m\" + str(m) + \"/EW_obs_\" + data_file_names[data] + \"_selection\" + str(run) + \\\n",
    "                            \"_line\" + str(lines[l]) + \"_bins\" + str(N) + \"_ML\" + str(m) + \".txt\", EW_obs_all)\n",
    "        np.savez_compressed(server_paths[server] + \"ew_results/\" + data_file_names[data] + \"/m\" + str(m) + \"/line_ivars_\" + data_file_names[data] + \"_selection\" + str(run) + \\\n",
    "                            \"_line\" + str(lines[l]) + \"_bins\" + str(N) + \"_ML\" + str(m) + \".txt\", line_ivars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749df013-9bf5-4681-be0e-836932051016",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(EWs[:,l]==np.max(EWs[:,l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745208e1-b4c5-4138-8fef-2a975c4d2d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(select_fluxes)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b73496-9cad-4755-9b14-b13f62aeb59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fastspec=0.795, fastphot=0.8153 ,raw=0.785, raw_unmasked=0.898 this is for 10k\n",
    "#fastspec=0.787, fastphot=0.821, raw=0.785, raw_unmasked=0.9 this is for 30k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cada98-dff3-4b09-b2ef-7f8006f30f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(EW_obs_all[0][:],EW_fit_all[0][:],'*',alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c81fb24-55a0-498a-8cbf-552af057f523",
   "metadata": {},
   "outputs": [],
   "source": [
    "if m == 4:\n",
    "    plt.plot(history.history[\"val_loss\"])\n",
    "    plt.plot(history.history[\"loss\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13b8c54-eb94-43da-92b8-6216a762003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if perlmutter:\n",
    "    spectra = np.load(\"/pscratch/sd/a/ashodkh/spectra_from_targets/raw/raw_spectra\" +str(0)+ \"_selection\"+str(run)+\"_\"+str(lines[l])+\".txt.npz\")[\"arr_0\"]\n",
    "    #spectra = np.load(\"/pscratch/sd/a/ashodkh/spectra_from_targets/fastphot/fastphot_spectra\" +str(1)+ \"_selection\"+str(run)+\"_\"+str(lines[l])+\".txt.npz\")[\"arr_0\"]\n",
    "    #spectra = np.load(\"/pscratch/sd/a/ashodkh/spectra_from_targets/fastspec/fastspec_spectra\" +str(1)+ \"_selection\"+str(run)+\"_\"+str(lines[l])+\".txt.npz\")[\"arr_0\"]\n",
    "\n",
    "    #spectra = spectra[select_fluxes[10*10**3:20*10**3],:]\n",
    "    spectra = spectra[select_fluxes[:10*10**3],:]\n",
    "if cori:\n",
    "    if fastspec:\n",
    "        spectra = np.load(\"/global/cscratch1/sd/ashodkh/spectra_from_targets/fastspec/fastspec_spectra\" +str(0)+ \"_selection\"+str(run)+\"_\"+str(lines[l])+\".txt.npz\")[\"arr_0\"]\n",
    "    if fastphot:\n",
    "        spectra = np.load(\"/global/cscratch1/sd/ashodkh/spectra_from_targets/fastphot/fastphot_spectra\" +str(0)+ \"_selection\"+str(run)+\"_\"+str(lines[l])+\".txt.npz\")[\"arr_0\"]\n",
    "    if raw:\n",
    "        spectra = np.load(\"/global/cscratch1/sd/ashodkh/spectra_from_targets/raw/raw_spectra\" +str(0)+ \"_selection\"+str(run)+\"_\"+str(lines[l])+\".txt.npz\")[\"arr_0\"]\n",
    "    if raw_unmasked:\n",
    "        spectra = np.load(\"/global/cscratch1/sd/ashodkh/spectra_from_targets/raw/raw_spectra\" +str(0)+ \"_selection\"+str(run)+\"_\"+str(lines[l])+\".txt.npz\")[\"arr_0\"]\n",
    "    spectra = spectra[select_fluxes[:10*10**3],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f858603-c141-4feb-9b80-cf62e083a6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = 3400, 7000\n",
    "d = np.average(.8/(1+zs))\n",
    "Ns = [16]\n",
    "pivot = []\n",
    "effective_waves = []\n",
    "wavelength = np.arange(3600, 9824+.8, .8)\n",
    "c=3*10**18\n",
    "for N in Ns:\n",
    "    print(N)\n",
    "    bin_ws = np.linspace(w1,w2,N)\n",
    "    small_bins = []\n",
    "    pivot_bins = []\n",
    "    effective_waves_bins = []\n",
    "    for i in range(N-1):\n",
    "        small_bins.append(np.arange(bin_ws[i],bin_ws[i+1],d))\n",
    "        pivot_bins.append(np.sqrt(np.average(small_bins[i])/np.average(1/small_bins[i])))\n",
    "        effective_waves_bins.append(np.average(small_bins[i]))\n",
    "\n",
    "    pivot.append(pivot_bins)\n",
    "    effective_waves.append(effective_waves_bins)\n",
    "\n",
    "i = 4305\n",
    "\n",
    "plt.figure(1)\n",
    "#plt.plot(wavelength/(1+zs[select_fluxes][i]), signal.medfilt(spectra[i-len(np.where(select_fluxes[:10*10**3])[0]),:], kernel_size=15)*(1+zs[select_fluxes][i]))\n",
    "plt.plot(wavelength/(1+zs[select_fluxes][i]), signal.medfilt(spectra[i,:], kernel_size=15)*(1+zs[select_fluxes][i]))\n",
    "plt.plot(effective_waves[0], fluxes_bin[i,:]*c/np.array(pivot[0])[:]**2, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85cadb4-0fc1-4146-a864-fb30fa03c5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = 3400, 7000\n",
    "d = np.average(.8/(1+zs))\n",
    "Ns = [16]\n",
    "pivot = []\n",
    "effective_waves = []\n",
    "wavelength = np.arange(3600, 9824+.8, .8)\n",
    "c=3*10**18\n",
    "for N in Ns:\n",
    "    print(N)\n",
    "    bin_ws = np.linspace(w1,w2,N)\n",
    "    small_bins = []\n",
    "    pivot_bins = []\n",
    "    effective_waves_bins = []\n",
    "    for i in range(N-1):\n",
    "        small_bins.append(np.arange(bin_ws[i],bin_ws[i+1],d))\n",
    "        pivot_bins.append(np.sqrt(np.average(small_bins[i])/np.average(1/small_bins[i])))\n",
    "        effective_waves_bins.append(np.average(small_bins[i]))\n",
    "\n",
    "    pivot.append(pivot_bins)\n",
    "    effective_waves.append(effective_waves_bins)\n",
    "\n",
    "i = 4999\n",
    "\n",
    "plt.figure(1)\n",
    "#plt.plot(wavelength/(1+zs[select_fluxes][i]), signal.medfilt(spectra[i-len(np.where(select_fluxes[:10*10**3])[0]),:], kernel_size=15)*(1+zs[select_fluxes][i]))\n",
    "plt.plot(wavelength/(1+zs[select_fluxes][i]), signal.medfilt(spectra[i,:], kernel_size=15)*(1+zs[select_fluxes][i]))\n",
    "plt.plot(effective_waves[0], fluxes_bin[i,:]*c/np.array(pivot[0])[:]**2, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a77f1f9-4740-43cc-ad06-742a37585908",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
