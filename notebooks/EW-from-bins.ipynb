{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eeae0c6-7960-45c3-bd66-2c98f705678e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/a/ashodkh/.conda/envs/myenv/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pylab as plt\n",
    "from scipy import stats, signal\n",
    "from sklearn.neighbors import KDTree\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from os import listdir\n",
    "import scipy\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from LLR import LLR\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "plt.rcParams['figure.figsize'] = [25, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fade9c2-c730-4486-8995-7e5e0d9d1bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_and_outcomes(x_in, y_in, n_out, ivar):\n",
    "    magnitudes = np.zeros([n_out,x_in.shape[1]])\n",
    "    EWs = np.zeros([n_out,len(lines)])\n",
    "    \n",
    "    select_fluxes = x_in[:,0]>0\n",
    "    for i in range(1, x_in.shape[1]):\n",
    "        select_fluxes = select_fluxes*(x_in[:,i]>0)\n",
    "    \n",
    "    x_in = x_in[select_fluxes,:]\n",
    "    y_in = y_in[select_fluxes]\n",
    "    ivar = ivar[select_fluxes]\n",
    "    \n",
    "    for i in range(n_out):\n",
    "        magnitudes[i,:] = -2.5*np.log10(x_in[i,:])\n",
    "        for j in range(len(lines)):\n",
    "            EWs[i,j] = y_in[i][j]\n",
    "    \n",
    "    ones = np.ones([n_out,1])\n",
    "    scalar = StandardScaler()\n",
    "    x_out = np.zeros([n_out,x_in.shape[1]-1])\n",
    "    for j in range(x_in.shape[1]-1):\n",
    "        x_out[:,j] = magnitudes[:,j] - magnitudes[:,j+1]\n",
    "    x_out = scalar.fit_transform(x_out)\n",
    "    \n",
    "    if (m == 0 or m == 5) or (m == 6 or m == 7):\n",
    "        x_out = np.concatenate((ones,x_out), axis=1)\n",
    "        \n",
    "    if loga:\n",
    "        y_out = np.log10(EWs[:,l])\n",
    "    else:\n",
    "        y_out = EWs[:,l]\n",
    "        \n",
    "    return x_out, y_out, ivar\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d5a3e3-bfe5-40b5-87f0-2451fc6b61dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "HALPHA_EW\n",
      "[0.8239675708710646, 0.8555385526783092, 0.8258609872179065, 0.7971838055003495, 0.8433848616573666, 0.8076193495129861, 0.8278853048521575, 0.8376198729781957, 0.8350893637466537, 0.845338375629018]\n",
      "spearman_average= 0.8299488044644008\n",
      "[0.27616096731961165, 0.2915424976341893, 0.28499469911660325, 0.3148310685551887, 0.28103630270653485, 0.3252640448439384, 0.30119539904259135, 0.31387914090594715, 0.2935715990286196, 0.3098011520767034]\n",
      "nmad_average= 0.29922768712299275\n",
      "\n",
      "\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "server = 1 # 0 is perlmutter, 1 is cori\n",
    "server_paths = ['/pscratch/sd/a/ashodkh/', '/global/cscratch1/sd/ashodkh/']\n",
    "\n",
    "## reading fluxes and equivalent widths\n",
    "lines = [\"OII_DOUBLET_EW\",\"HGAMMA_EW\",\"HBETA_EW\",\"OIII_4959_EW\",\"OIII_5007_EW\",\"NII_6548_EW\"\\\n",
    "         ,\"HALPHA_EW\",\"NII_6584_EW\",\"SII_6716_EW\",\"SII_6731_EW\"]\n",
    "l = 6\n",
    "\n",
    "run = 0\n",
    "m = 7\n",
    "loga = True\n",
    "\n",
    "data = 0 # 0 is raw_masked, 1 is raw_unmasked, 2 is fastspec, 3 is fastphot\n",
    "data_file_names = ['raw_masked', 'raw_unmasked', 'fastspec', 'fastphot']\n",
    "data_flux_names = ['fluxes', 'fluxes', 'fluxes_fastspec', 'fluxes_fastphot']\n",
    "\n",
    "Ns = [6, 11, 16, 21, 26, 31, 41, 51]\n",
    "decades = 3 ## number of 10k galaxy files I want to load and combine\n",
    "for N in Ns:\n",
    "    n = 10*10**3\n",
    "    fluxes_bin = np.zeros([25*10**3, N-1]) ## fluxes are separated into groups of 10k galaxies\n",
    "    for i in range(decades):\n",
    "        if i == 2:\n",
    "            n = 5*10**3\n",
    "            fluxes_bin[10**4*i:25*10**3,:] =  np.load(server_paths[server] + \"fluxes_from_spectra/\" + data_file_names[data] + \"/\" + data_flux_names[data]\\\n",
    "                                                +str(i)+ \"_selection\"+str(run)+\"_\"+str(lines[l])+\"_bins\"+str(N)+\".txt.npz\")[\"arr_0\"]\n",
    "        else:\n",
    "            fluxes_bin[10**4*i:n*(i+1),:] = np.load(server_paths[server] + \"fluxes_from_spectra/\" + data_file_names[data] + \"/\" + data_flux_names[data]\\\n",
    "                                            +str(i)+ \"_selection\"+str(run)+\"_\"+str(lines[l])+\"_bins\"+str(N)+\".txt.npz\")[\"arr_0\"]\n",
    "\n",
    "        zs = np.load(\"/global/cscratch1/sd/ashodkh/target_selection/zs_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt.npz\")[\"arr_0\"][:decades*10*10**3]\n",
    "        target_lines = np.load(\"/global/cscratch1/sd/ashodkh/target_selection/line_ews_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt.npz\")[\"arr_0\"][:decades*10*10**3]\n",
    "        line_ivars = np.load(\"/global/cscratch1/sd/ashodkh/target_selection/line_ivars_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt.npz\")[\"arr_0\"][:decades*10*10**3]\n",
    "\n",
    "    x, EW, line_ivars = features_and_outcomes(fluxes_bin, target_lines, 23*10**3,line_ivars) \n",
    "    \n",
    "    N_cv = 10\n",
    "    x_split = np.split(x,N_cv)\n",
    "    EW_split = np.split(EW,N_cv)\n",
    "\n",
    "    EW_fit_all = []\n",
    "    EW_obs_all = []\n",
    "\n",
    "    spearman_all = []\n",
    "    rms_all = []\n",
    "    nmad_all = []\n",
    "    nmad2_all = []\n",
    "    for i in range(N_cv):\n",
    "        ## assigning the training and validation sets\n",
    "        x_valid = x_split[i]\n",
    "        EW_valid = EW_split[i]\n",
    "\n",
    "        x_to_combine = []\n",
    "        EW_to_combine = []\n",
    "        for j in range(N_cv):\n",
    "            if j != i:\n",
    "                x_to_combine.append(x_split[j])\n",
    "                EW_to_combine.append(EW_split[j])\n",
    "        x_train=np.concatenate(tuple(x_to_combine),axis=0)\n",
    "        EW_train=np.concatenate(tuple(EW_to_combine),axis=0)\n",
    "\n",
    "        # predicting EWs using different models\n",
    "        if m == 0:\n",
    "            EW_fit,zeros = LLR.LLR(x_valid, x_train, EW_train, 100, 'inverse_distance')\n",
    "        if m == 1:\n",
    "            model = RandomForestRegressor(n_estimators=200)\n",
    "            model.fit(x_train, EW_train)\n",
    "            EW_fit = model.predict(x_valid)\n",
    "        if m == 2:\n",
    "            model = GradientBoostingRegressor(n_estimators=100)\n",
    "            model.fit(x_train, EW_train)\n",
    "            EW_fit = model.predict(x_valid)\n",
    "        if m == 3:\n",
    "            model = xgb.XGBRegressor(n_estimators=1000, learning_rate=0.05)\n",
    "            model.fit(x_train, EW_train, early_stopping_rounds=5, eval_set=[(x_valid,EW_valid)], verbose=False)\n",
    "            EW_fit = model.predict(x_valid)\n",
    "            print(model.best_ntree_limit)\n",
    "        if m == 4:\n",
    "            model_input = layers.Input(shape=x.shape[1])\n",
    "            h1 = layers.Dense(units=100, kernel_initializer=\"he_normal\")(model_input)\n",
    "            a1 = layers.PReLU()(h1)\n",
    "            h2 = layers.Dense(units=100, kernel_initializer=\"he_normal\")(a1)\n",
    "            a2 = layers.PReLU()(h2)\n",
    "            h3 = layers.Dense(units=100, kernel_initializer=\"he_normal\")(a2)\n",
    "            a3 = layers.PReLU()(h3)\n",
    "            output_layer = layers.Dense(1, activation='linear')(a3)\n",
    "            model = keras.models.Model(inputs=model_input, outputs=output_layer)\n",
    "\n",
    "            model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3), loss='mse', metrics='mse')\n",
    "\n",
    "            n_epochs = 100\n",
    "            batch_size = 100\n",
    "            history = model.fit(x_train, EW_train, batch_size=batch_size, epochs=n_epochs, verbose=0, validation_data=(x_valid, EW_valid))\n",
    "            EW_fit = model.predict(x_valid)\n",
    "        if m == 5:\n",
    "            EW_fit,zeros = LLR.LLR(x_valid, x_train, EW_train, 200, 'inverse_distance')\n",
    "        if m == 6:\n",
    "            EW_fit,zeros = LLR.LLR(x_valid, x_train, EW_train, 800, 'inverse_distance')\n",
    "        if m == 7:\n",
    "            EW_fit,zeros = LLR.LLR(x_valid, x_train, EW_train, 1000, 'inverse_distance')\n",
    "            \n",
    "        # calculating spearman coefficient and nmad for fit. nmad2 has the error in it.\n",
    "        nmad = np.abs(EW_fit-EW_valid)\n",
    "        nmad2 = np.abs(EW_fit-EW_valid)\n",
    "\n",
    "        EW_fit_all.append(EW_fit)\n",
    "        EW_obs_all.append(EW_valid)\n",
    "\n",
    "        spearman_all.append(stats.spearmanr(EW_fit,EW_valid)[0])\n",
    "        rms_all.append(np.sqrt(mean_squared_error(EW_fit,EW_valid)))\n",
    "        nmad_all.append(1.48*np.median(nmad))\n",
    "        nmad2_all.append(1.48*np.median(nmad2))\n",
    "\n",
    "    print(lines[l])\n",
    "    print(spearman_all)\n",
    "    print('spearman_average= '+str(np.average(spearman_all)))\n",
    "    # print(rms_all)\n",
    "    # print(np.average(rms_all))\n",
    "    print(nmad_all)\n",
    "    print('nmad_average= '+str(np.average(nmad_all)))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    if loga:\n",
    "        np.savez_compressed(server_paths[server] + \"ew_results/\" + data_file_names[data] + \"/m\" + str(m) + \"/logEW_fit_\" + data_file_names[data] + \"_selection\" + str(run) + \\\n",
    "                            \"_line\" + str(lines[l]) + \"_bins\" + str(N) + \"_ML\" + str(m) + \".txt\", EW_fit_all)\n",
    "        np.savez_compressed(server_paths[server] + \"ew_results/\" + data_file_names[data] + \"/m\" + str(m) + \"/logEW_obs_\" + data_file_names[data] + \"_selection\" + str(run) + \\\n",
    "                            \"_line\" + str(lines[l]) + \"_bins\" + str(N) + \"_ML\" + str(m) + \".txt\", EW_obs_all)\n",
    "        np.savez_compressed(server_paths[server] + \"ew_results/\" + data_file_names[data] + \"/m\" + str(m) + \"/line_ivars_\" + data_file_names[data] + \"_selection\" + str(run) + \\\n",
    "                            \"_line\" + str(lines[l]) + \"_bins\" + str(N) + \"_ML\" + str(m) + \".txt\", line_ivars)\n",
    "    else:\n",
    "        np.savez_compressed(server_paths[server] + \"ew_results/\" + data_file_names[data] + \"/m\" + str(m) + \"/EW_fit_\" + data_file_names[data] + \"_selection\" + str(run) + \\\n",
    "                            \"_line\" + str(lines[l]) + \"_bins\" + str(N) + \"_ML\" + str(m) + \".txt\", EW_fit_all)\n",
    "        np.savez_compressed(server_paths[server] + \"ew_results/\" + data_file_names[data] + \"/m\" + str(m) + \"/EW_obs_\" + data_file_names[data] + \"_selection\" + str(run) + \\\n",
    "                            \"_line\" + str(lines[l]) + \"_bins\" + str(N) + \"_ML\" + str(m) + \".txt\", EW_obs_all)\n",
    "        np.savez_compressed(server_paths[server] + \"ew_results/\" + data_file_names[data] + \"/m\" + str(m) + \"/line_ivars_\" + data_file_names[data] + \"_selection\" + str(run) + \\\n",
    "                            \"_line\" + str(lines[l]) + \"_bins\" + str(N) + \"_ML\" + str(m) + \".txt\", line_ivars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749df013-9bf5-4681-be0e-836932051016",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(EWs[:,l]==np.max(EWs[:,l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745208e1-b4c5-4138-8fef-2a975c4d2d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(select_fluxes)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b73496-9cad-4755-9b14-b13f62aeb59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fastspec=0.795, fastphot=0.8153 ,raw=0.785, raw_unmasked=0.898 this is for 10k\n",
    "#fastspec=0.787, fastphot=0.821, raw=0.785, raw_unmasked=0.9 this is for 30k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cada98-dff3-4b09-b2ef-7f8006f30f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(EW_obs_all[0][:],EW_fit_all[0][:],'*',alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c81fb24-55a0-498a-8cbf-552af057f523",
   "metadata": {},
   "outputs": [],
   "source": [
    "if m == 4:\n",
    "    plt.plot(history.history[\"val_loss\"])\n",
    "    plt.plot(history.history[\"loss\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13b8c54-eb94-43da-92b8-6216a762003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if perlmutter:\n",
    "    spectra = np.load(\"/pscratch/sd/a/ashodkh/spectra_from_targets/raw/raw_spectra\" +str(0)+ \"_selection\"+str(run)+\"_\"+str(lines[l])+\".txt.npz\")[\"arr_0\"]\n",
    "    #spectra = np.load(\"/pscratch/sd/a/ashodkh/spectra_from_targets/fastphot/fastphot_spectra\" +str(1)+ \"_selection\"+str(run)+\"_\"+str(lines[l])+\".txt.npz\")[\"arr_0\"]\n",
    "    #spectra = np.load(\"/pscratch/sd/a/ashodkh/spectra_from_targets/fastspec/fastspec_spectra\" +str(1)+ \"_selection\"+str(run)+\"_\"+str(lines[l])+\".txt.npz\")[\"arr_0\"]\n",
    "\n",
    "    #spectra = spectra[select_fluxes[10*10**3:20*10**3],:]\n",
    "    spectra = spectra[select_fluxes[:10*10**3],:]\n",
    "if cori:\n",
    "    if fastspec:\n",
    "        spectra = np.load(\"/global/cscratch1/sd/ashodkh/spectra_from_targets/fastspec/fastspec_spectra\" +str(0)+ \"_selection\"+str(run)+\"_\"+str(lines[l])+\".txt.npz\")[\"arr_0\"]\n",
    "    if fastphot:\n",
    "        spectra = np.load(\"/global/cscratch1/sd/ashodkh/spectra_from_targets/fastphot/fastphot_spectra\" +str(0)+ \"_selection\"+str(run)+\"_\"+str(lines[l])+\".txt.npz\")[\"arr_0\"]\n",
    "    if raw:\n",
    "        spectra = np.load(\"/global/cscratch1/sd/ashodkh/spectra_from_targets/raw/raw_spectra\" +str(0)+ \"_selection\"+str(run)+\"_\"+str(lines[l])+\".txt.npz\")[\"arr_0\"]\n",
    "    if raw_unmasked:\n",
    "        spectra = np.load(\"/global/cscratch1/sd/ashodkh/spectra_from_targets/raw/raw_spectra\" +str(0)+ \"_selection\"+str(run)+\"_\"+str(lines[l])+\".txt.npz\")[\"arr_0\"]\n",
    "    spectra = spectra[select_fluxes[:10*10**3],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f858603-c141-4feb-9b80-cf62e083a6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = 3400, 7000\n",
    "d = np.average(.8/(1+zs))\n",
    "Ns = [16]\n",
    "pivot = []\n",
    "effective_waves = []\n",
    "wavelength = np.arange(3600, 9824+.8, .8)\n",
    "c=3*10**18\n",
    "for N in Ns:\n",
    "    print(N)\n",
    "    bin_ws = np.linspace(w1,w2,N)\n",
    "    small_bins = []\n",
    "    pivot_bins = []\n",
    "    effective_waves_bins = []\n",
    "    for i in range(N-1):\n",
    "        small_bins.append(np.arange(bin_ws[i],bin_ws[i+1],d))\n",
    "        pivot_bins.append(np.sqrt(np.average(small_bins[i])/np.average(1/small_bins[i])))\n",
    "        effective_waves_bins.append(np.average(small_bins[i]))\n",
    "\n",
    "    pivot.append(pivot_bins)\n",
    "    effective_waves.append(effective_waves_bins)\n",
    "\n",
    "i = 4305\n",
    "\n",
    "plt.figure(1)\n",
    "#plt.plot(wavelength/(1+zs[select_fluxes][i]), signal.medfilt(spectra[i-len(np.where(select_fluxes[:10*10**3])[0]),:], kernel_size=15)*(1+zs[select_fluxes][i]))\n",
    "plt.plot(wavelength/(1+zs[select_fluxes][i]), signal.medfilt(spectra[i,:], kernel_size=15)*(1+zs[select_fluxes][i]))\n",
    "plt.plot(effective_waves[0], fluxes_bin[i,:]*c/np.array(pivot[0])[:]**2, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85cadb4-0fc1-4146-a864-fb30fa03c5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = 3400, 7000\n",
    "d = np.average(.8/(1+zs))\n",
    "Ns = [16]\n",
    "pivot = []\n",
    "effective_waves = []\n",
    "wavelength = np.arange(3600, 9824+.8, .8)\n",
    "c=3*10**18\n",
    "for N in Ns:\n",
    "    print(N)\n",
    "    bin_ws = np.linspace(w1,w2,N)\n",
    "    small_bins = []\n",
    "    pivot_bins = []\n",
    "    effective_waves_bins = []\n",
    "    for i in range(N-1):\n",
    "        small_bins.append(np.arange(bin_ws[i],bin_ws[i+1],d))\n",
    "        pivot_bins.append(np.sqrt(np.average(small_bins[i])/np.average(1/small_bins[i])))\n",
    "        effective_waves_bins.append(np.average(small_bins[i]))\n",
    "\n",
    "    pivot.append(pivot_bins)\n",
    "    effective_waves.append(effective_waves_bins)\n",
    "\n",
    "i = 4999\n",
    "\n",
    "plt.figure(1)\n",
    "#plt.plot(wavelength/(1+zs[select_fluxes][i]), signal.medfilt(spectra[i-len(np.where(select_fluxes[:10*10**3])[0]),:], kernel_size=15)*(1+zs[select_fluxes][i]))\n",
    "plt.plot(wavelength/(1+zs[select_fluxes][i]), signal.medfilt(spectra[i,:], kernel_size=15)*(1+zs[select_fluxes][i]))\n",
    "plt.plot(effective_waves[0], fluxes_bin[i,:]*c/np.array(pivot[0])[:]**2, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a77f1f9-4740-43cc-ad06-742a37585908",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
