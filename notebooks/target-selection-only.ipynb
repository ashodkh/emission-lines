{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5ba0bcb-1dd5-410a-a7d9-b7d08d7a9375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.table import Table, join\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import random\n",
    "from scipy import stats\n",
    "from sklearn.neighbors import KDTree\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "from os import listdir\n",
    "import scipy\n",
    "from desitarget.targetmask import desi_mask, bgs_mask, mws_mask\n",
    "from desitarget.cmx.cmx_targetmask import cmx_mask\n",
    "plt.rcParams['figure.figsize'] = [25, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "559a2b72-1d78-46fc-87ff-578ba3226893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: Cannot merge meta key 'EXTNAME' types <class 'str'> and <class 'str'>, choosing EXTNAME='FASTSPEC' [astropy.utils.metadata]\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'EXTNAME' types <class 'str'> and <class 'str'>, choosing EXTNAME='FASTPHOT' [astropy.utils.metadata]\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'CHECKSUM' types <class 'str'> and <class 'str'>, choosing CHECKSUM='caYXdTXWcYXWcYXW' [astropy.utils.metadata]\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATASUM' types <class 'str'> and <class 'str'>, choosing DATASUM='3872209941' [astropy.utils.metadata]\n",
      "/tmp/ipykernel_58418/3233417951.py:42: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  data.add_column(1/(data[\"OII_3726_EW_IVAR\"]+data[\"OII_3729_EW_IVAR\"]), name='OII_DOUBLET_EW_IVAR')\n"
     ]
    }
   ],
   "source": [
    "server = 1 # 0 is perlmutter, 1 is cori\n",
    "server_paths = ['/pscratch/sd/a/ashodkh/', '/global/cscratch1/sd/ashodkh/']\n",
    "## DATA ##\n",
    "## I'm combining fastphot,fastspect, and ztile to make sure I use the same data everywhere\n",
    "\n",
    "test = False\n",
    "train = True\n",
    "\n",
    "if test:\n",
    "    sv = '3'\n",
    "if train:\n",
    "    sv = '1'\n",
    "zall_path = \"/global/cfs/cdirs/desi/spectro/redux/fuji/zcatalog/ztile-sv\"+sv+\"-bright-cumulative.fits\"\n",
    "data1 = Table.read(zall_path,hdu=1)\n",
    "needed1 = [\"TARGETID\", \"SV\"+sv+\"_BGS_TARGET\", \"SPECTYPE\", \"DELTACHI2\", \"Z\", \"ZWARN\", \"FIBER\", \"PETAL_LOC\", \"TILEID\"]\n",
    "\n",
    "fastspec_path = \"/global/cfs/cdirs/desi/spectro/fastspecfit/fuji/catalogs/fastspec-fuji-sv\"+sv+\"-bright.fits\"\n",
    "data2 = Table.read(fastspec_path,hdu=1)\n",
    "data2.rename_column('CONTINUUM_COEFF', 'CONTINUUM_COEFF_FASTSPEC')\n",
    "data2.rename_column('CONTINUUM_AV', 'CONTINUUM_AV_FASTSPEC')\n",
    "\n",
    "needed2 = [\"TARGETID\", \"OII_3726_EW\", \"OII_3729_EW\", \"HGAMMA_EW\", \"HBETA_EW\", \"OIII_4959_EW\", \"OIII_5007_EW\", \"NII_6548_EW\", \"HALPHA_EW\", \"NII_6584_EW\", \"SII_6716_EW\", \"SII_6731_EW\",\\\n",
    "           \"FLUX_SYNTH_G\", \"FLUX_SYNTH_R\", \"FLUX_SYNTH_Z\", 'CONTINUUM_COEFF_FASTSPEC', 'CONTINUUM_AV_FASTSPEC',\\\n",
    "           \"OII_3726_EW_IVAR\", \"OII_3729_EW_IVAR\", \"HGAMMA_EW_IVAR\", \"HBETA_EW_IVAR\", \"OIII_4959_EW_IVAR\", \"OIII_5007_EW_IVAR\", \"NII_6548_EW_IVAR\", \"HALPHA_EW_IVAR\", \"NII_6584_EW_IVAR\",\\\n",
    "           \"SII_6716_EW_IVAR\", \"SII_6731_EW_IVAR\", \"CONTINUUM_SMOOTHCORR_B\", \"CONTINUUM_SMOOTHCORR_R\", \"CONTINUUM_SMOOTHCORR_Z\"]\n",
    "\n",
    "\n",
    "fastphot_path = \"/global/cfs/cdirs/desi/spectro/fastspecfit/fuji/catalogs/fastphot-fuji-sv\"+sv+\"-bright.fits\"\n",
    "data3 = Table.read(fastphot_path,hdu=1)\n",
    "data3.rename_column('CONTINUUM_COEFF', 'CONTINUUM_COEFF_FASTPHOT')\n",
    "data3.rename_column('CONTINUUM_AV', 'CONTINUUM_AV_FASTPHOT')\n",
    "\n",
    "needed3 = [\"TARGETID\", \"ABSMAG_SDSS_U\", \"ABSMAG_SDSS_G\", \"ABSMAG_SDSS_R\", \"ABSMAG_SDSS_I\", \"ABSMAG_SDSS_Z\", 'ABSMAG_W1', 'CONTINUUM_COEFF_FASTPHOT', 'CONTINUUM_AV_FASTPHOT']\n",
    "\n",
    "data4 = join(data1[needed1], data2[needed2], keys=\"TARGETID\")\n",
    "data = join(data4, data3[needed3], keys=\"TARGETID\")\n",
    "\n",
    "N=len(data['TARGETID'])\n",
    "\n",
    "## Adding the sum of OII doublets to use them as a single line\n",
    "data.add_column(data[\"OII_3726_EW\"]+data[\"OII_3729_EW\"], name='OII_DOUBLET_EW')\n",
    "data.add_column(1/(data[\"OII_3726_EW_IVAR\"]+data[\"OII_3729_EW_IVAR\"]), name='OII_DOUBLET_EW_IVAR')\n",
    "\n",
    "not_used, ind = np.unique(data['TARGETID'], return_index=True)\n",
    "data = data[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02cf56ce-31e7-4654-a6cd-136722de9144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size after selection: 36223\n",
      "data_train size before any snr cuts: 36223\n",
      "size after halpha cut: 28521\n",
      "size after snr cuts: 26730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_58418/4023081720.py:98: RuntimeWarning: invalid value encountered in multiply\n",
      "  snr_all[:,0] = data_select[lines[0]]*np.sqrt(data_select[lines[0]+\"_IVAR\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size after snr cuts: 25142\n",
      "size after snr cuts: 26666\n",
      "size after snr cuts: 26684\n",
      "size after snr cuts: 26686\n",
      "size after snr cuts: 28393\n",
      "size after snr cuts: 28521\n",
      "size after snr cuts: 28394\n",
      "size after snr cuts: 27568\n",
      "size after snr cuts: 27568\n"
     ]
    }
   ],
   "source": [
    "lines = [\"OII_DOUBLET_EW\", \"HGAMMA_EW\", \"HBETA_EW\", \"OIII_4959_EW\", \"OIII_5007_EW\", \"NII_6548_EW\", \"HALPHA_EW\", \"NII_6584_EW\", \"SII_6716_EW\", \"SII_6731_EW\", \"test\"]\n",
    "lines_ivar = [\"OII_DOUBLET_EW_IVAR\", \"HGAMMA_EW_IVAR\", \"HBETA_EW_IVAR\", \"OIII_4959_EW_IVAR\", \"OIII_5007_EW_IVAR\", \"NII_6548_EW_IVAR\", \"HALPHA_EW_IVAR\", \"NII_6584_EW_IVAR\",\\\n",
    "              \"SII_6716_EW_IVAR\", \"SII_6731_EW_IVAR\"]\n",
    "\n",
    "magnitude_names = [\"ABSMAG_SDSS_U\", \"ABSMAG_SDSS_G\", \"ABSMAG_SDSS_R\", \"ABSMAG_SDSS_I\", \"ABSMAG_SDSS_Z\", \"ABSMAG_W1\"]\n",
    "    \n",
    "# calculating minimum redshift to have de-redshifted wavelengths be in the interval w1,w2 A\n",
    "w1 = 3400\n",
    "w_min = 3600\n",
    "z_min = w_min/w1-1\n",
    "w2 = 8500\n",
    "w_max = 9824\n",
    "#z_max = w_max/w2-1\n",
    "z_max = 0.3\n",
    "\n",
    "# target selection index. run should be changed if anything in select changed and/or the number of data points changed\n",
    "if test:\n",
    "    run = 2\n",
    "if train:\n",
    "    run = 2 # old run=0 was sv1 with no bgs selection and n=30k. new run=0 is sv1 with bgs selection. There's only about 25k per line so I will use them for training only.\n",
    "        # run 1 is sv3 with bgs selection. So far I'm only using it for testing so only l=10.\n",
    "        # run 2 is no zero EWs for test set and line_ews and line_ivar are better structured.\n",
    "\n",
    "## I am splitting data into training and testing before applying snr_cuts, and then saving them separately\n",
    "\n",
    "    \n",
    "select = ((data[\"SV\"+sv+\"_BGS_TARGET\"] & bgs_mask.mask(\"BGS_BRIGHT\"))>0)*(data[\"SPECTYPE\"]==\"GALAXY\")*(data[\"DELTACHI2\"]>=25)\\\n",
    "         *(data[\"Z\"]>z_min)*(data[\"Z\"]<z_max)*(data[\"ZWARN\"]==0)\n",
    "\n",
    "select_size = len(np.where(select)[0])\n",
    "print('data size after selection: ' + str(select_size))\n",
    "data_select = data[select]\n",
    "\n",
    "if test:\n",
    "    # no_zeros = (data_select[lines[0]] != 0)\n",
    "    # for l in range(1,len(lines)-1):\n",
    "    #     no_zeros = no_zeros * (data_select[lines[l]] != 0)\n",
    "    \n",
    "    for l in range(len(lines)-1):\n",
    "        no_zeros = (data_select[lines[l]] != 0)\n",
    "        data_test = data_select[no_zeros]\n",
    "        print('length of data_test is: ' + str(len(data_test)))\n",
    "\n",
    "        n_test = 20*10**3 # size of testing set I'm keeping\n",
    "\n",
    "        target_ids = data_test[\"TARGETID\"][:n_test]\n",
    "        fiber_ids = data_test[\"FIBER\"][:n_test]\n",
    "        petal_locs = data_test[\"PETAL_LOC\"][:n_test]\n",
    "        tile_ids = data_test[\"TILEID\"][:n_test]\n",
    "        zs = data_test[\"Z\"][:n_test]\n",
    "\n",
    "        coeffs_fastspec = data_test['CONTINUUM_COEFF_FASTSPEC'][:n_test]\n",
    "        AV_fastspec = data_test['CONTINUUM_AV_FASTSPEC'][:n_test]\n",
    "\n",
    "        coeffs_fastphot = data_test['CONTINUUM_COEFF_FASTPHOT'][:n_test]\n",
    "        AV_fastphot = data_test['CONTINUUM_AV_FASTPHOT'][:n_test]\n",
    "\n",
    "        line_ews = np.array([data_test[ll][:n_test] for ll in lines[:-1]])\n",
    "        line_ivars = np.array([data_test[ll][:n_test] for ll in lines_ivar])\n",
    "\n",
    "        smooth_correction_b = data_test['CONTINUUM_SMOOTHCORR_B'][:n_test]\n",
    "        smooth_correction_r = data_test['CONTINUUM_SMOOTHCORR_R'][:n_test]\n",
    "        smooth_correction_z = data_test['CONTINUUM_SMOOTHCORR_Z'][:n_test]\n",
    "        #l = 10 # l=10 corresponds to test set that has no snr cuts. This is a good way of separating those files without changing much of my code.\n",
    "        np.savez_compressed(server_paths[server]+\"target_selection/sv\" + sv + \"_target_ids_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", target_ids)\n",
    "        np.savez_compressed(server_paths[server]+\"target_selection/sv\" + sv + \"_fiber_ids_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", fiber_ids)\n",
    "        np.savez_compressed(server_paths[server]+\"target_selection/sv\" + sv + \"_petal_locs_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", petal_locs)\n",
    "        np.savez_compressed(server_paths[server]+\"target_selection/sv\" + sv + \"_tile_ids_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", tile_ids)\n",
    "        np.savez_compressed(server_paths[server]+\"target_selection/sv\" + sv + \"_zs_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", zs)\n",
    "        np.savez_compressed(server_paths[server]+\"target_selection/sv\" + sv + \"_line_ews_selection\"+str(run)+\"_\" + str(lines[l]) + \".txt\", line_ews)\n",
    "        np.savez_compressed(server_paths[server]+\"target_selection/sv\" + sv + \"_line_ivars_selection\"+str(run)+\"_\" + str(lines[l]) + \".txt\", line_ivars)\n",
    "\n",
    "\n",
    "        np.savez_compressed(server_paths[server]+\"target_selection/sv\" + sv + \"_fastspec_coeffs_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", coeffs_fastspec)\n",
    "        np.savez_compressed(server_paths[server]+\"target_selection/sv\" + sv + \"_fastspec_AV_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", AV_fastspec)\n",
    "\n",
    "        np.savez_compressed(server_paths[server]+\"target_selection/sv\" + sv + \"_fastphot_coeffs_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", coeffs_fastphot)\n",
    "        np.savez_compressed(server_paths[server]+\"target_selection/sv\" + sv + \"_fastphot_AV_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", AV_fastphot)\n",
    "\n",
    "        np.savez_compressed(server_paths[server]+\"target_selection/sv\" + sv + \"_smooth_correction_b_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", smooth_correction_b)\n",
    "        np.savez_compressed(server_paths[server]+\"target_selection/sv\" + sv + \"_smooth_correction_r_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", smooth_correction_r)\n",
    "        np.savez_compressed(server_paths[server]+\"target_selection/sv\" + sv + \"_smooth_correction_z_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", smooth_correction_z)\n",
    "        # storing magnitudes to use in EW-from-ugriz-train-test\n",
    "        mags = np.zeros([n_test, len(magnitude_names)])\n",
    "        for i in range(len(magnitude_names)):\n",
    "            mags[:,i] = data_test[magnitude_names[i]][:n_test]\n",
    "            np.savez_compressed(server_paths[server]+\"target_selection/sv\" + sv + \"_\" + magnitude_names[i] + \"_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", mags[:,i])\n",
    "\n",
    "if train:\n",
    "    lines = [\"OII_DOUBLET_EW\", \"HGAMMA_EW\", \"HBETA_EW\", \"OIII_4959_EW\", \"OIII_5007_EW\", \"NII_6548_EW\", \"HALPHA_EW\", \"NII_6584_EW\", \"SII_6716_EW\", \"SII_6731_EW\"]\n",
    "    \n",
    "    ## choosing what snr cuts to make on data_train\n",
    "    N = len(data_select)\n",
    "    print('data_train size before any snr cuts: ' + str(N))\n",
    "    snr_cut = 1\n",
    "    # calculating snr for all lines and setting the snr cut boolean as select_snr\n",
    "    snr_all = np.zeros([N,len(lines)])\n",
    "    snr_all[:,0] = data_select[lines[0]]*np.sqrt(data_select[lines[0]+\"_IVAR\"])\n",
    "\n",
    "    cut_Halpha = True # cut Halpha on all data and later cut snr>0 for every line separately\n",
    "    cut_all = False # cut on all lines together, which extremely restricts the data\n",
    "    for i in range(1,len(lines)):\n",
    "        snr_all[:,i] = data_select[lines[i]]*np.sqrt(data_select[lines[i]+\"_IVAR\"])\n",
    "        if cut_all:\n",
    "            select_snr = select_snr*(snr_all[:,i]>snr_cut)\n",
    "    if cut_Halpha:\n",
    "        select_snr = snr_all[:,6]>snr_cut\n",
    "    print('size after halpha cut: ' + str(len(np.where(select_snr)[0])))\n",
    "    \n",
    "    n_train = 25*10**3\n",
    "    for l in range(len(lines)):\n",
    "        select_snr_both = select_snr*(snr_all[:,l]>0)\n",
    "        data_train = data_select[select_snr_both]\n",
    "        print('size after snr cuts: ' + str(len(data_train)))\n",
    "\n",
    "        target_ids = data_train[\"TARGETID\"][:n_train]\n",
    "        fiber_ids = data_train[\"FIBER\"][:n_train]\n",
    "        petal_locs = data_train[\"PETAL_LOC\"][:n_train]\n",
    "        tile_ids = data_train[\"TILEID\"][:n_train]\n",
    "        zs = data_train[\"Z\"][:n_train]\n",
    "\n",
    "        coeffs_fastspec = data_train['CONTINUUM_COEFF_FASTSPEC'][:n_train]\n",
    "        AV_fastspec = data_train['CONTINUUM_AV_FASTSPEC'][:n_train]\n",
    "\n",
    "        coeffs_fastphot = data_train['CONTINUUM_COEFF_FASTPHOT'][:n_train]\n",
    "        AV_fastphot = data_train['CONTINUUM_AV_FASTPHOT'][:n_train]\n",
    "\n",
    "        line_ews = np.array([data_train[ll][:n_train] for ll in lines])\n",
    "        line_ivars = np.array([data_train[ll][:n_train] for ll in lines_ivar])\n",
    "    \n",
    "        np.savez_compressed(server_paths[server]+\"target_selection/sv\" + sv + \"_target_ids_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", target_ids)\n",
    "        np.savez_compressed(server_paths[server]+\"target_selection/sv\" + sv + \"_fiber_ids_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", fiber_ids)\n",
    "        np.savez_compressed(server_paths[server]+\"target_selection/sv\" + sv + \"_petal_locs_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", petal_locs)\n",
    "        np.savez_compressed(server_paths[server]+\"target_selection/sv\" + sv + \"_tile_ids_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", tile_ids)\n",
    "        np.savez_compressed(server_paths[server]+\"target_selection/sv\" + sv + \"_zs_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", zs)\n",
    "        np.savez_compressed(server_paths[server]+\"target_selection/sv\" + sv + \"_line_ews_selection\"+str(run)+\"_\" + str(lines[l]) + \".txt\", line_ews)\n",
    "        np.savez_compressed(server_paths[server]+\"target_selection/sv\" + sv + \"_line_ivars_selection\"+str(run)+\"_\" + str(lines[l]) + \".txt\", line_ivars)\n",
    "\n",
    "        np.savez_compressed(server_paths[server]+\"target_selection/sv\" + sv + \"_fastspec_coeffs_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", coeffs_fastspec)\n",
    "        np.savez_compressed(server_paths[server]+\"target_selection/sv\" + sv + \"_fastspec_AV_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", AV_fastspec)\n",
    "\n",
    "        np.savez_compressed(server_paths[server]+\"target_selection/sv\" + sv + \"_fastphot_coeffs_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", coeffs_fastphot)\n",
    "        np.savez_compressed(server_paths[server]+\"target_selection/sv\" + sv + \"_fastphot_AV_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", AV_fastphot)\n",
    "        \n",
    "        # storing magnitudes to use in EW-from-ugriz-train-test\n",
    "        mags = np.zeros([n_train, len(magnitude_names)])\n",
    "        for i in range(len(magnitude_names)):\n",
    "            mags[:,i] = data_train[magnitude_names[i]][:n_train]\n",
    "            np.savez_compressed(server_paths[server]+\"target_selection/sv\" + sv + \"_\" + magnitude_names[i] + \"_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", mags[:,i])\n",
    "\n",
    "# if train:\n",
    "#     for l in range(len(lines)):\n",
    "#         # select = ((data[\"SV3_BGS_TARGET\"] & bgs_mask.mask(\"BGS_BRIGHT\"))>0)*(data[\"SPECTYPE\"]==\"GALAXY\")*(data[\"DELTACHI2\"]>=25)\\\n",
    "#         #          *(data[\"Z\"]>z_min)*(data[\"Z\"]<z_max)*(data[\"ZWARN\"]==0)*(select_snr)*(snr_all[:,l]>0)\n",
    "#         #snr_cut = (select_snr)*(snr_all[:,l]>0)\n",
    "#         snr_cut = [True]*(len(data_train))\n",
    "#         print('size after snr cuts: ' + str(len(np.where(snr_cut)[0])))\n",
    "\n",
    "#         n_train = 25*10**3 # size of data set I'm keeping\n",
    "\n",
    "#         target_ids = data_train[\"TARGETID\"][snr_cut][:n_train]\n",
    "#         fiber_ids = data_train[\"FIBER\"][snr_cut][:n_train]\n",
    "#         petal_locs = data_train[\"PETAL_LOC\"][snr_cut][:n_train]\n",
    "#         tile_ids = data_train[\"TILEID\"][snr_cut][:n_train]\n",
    "#         zs = data_train[\"Z\"][snr_cut][:n_train]\n",
    "\n",
    "#         coeffs_fastspec = data_train['CONTINUUM_COEFF_FASTSPEC'][snr_cut][:n_train]\n",
    "#         AV_fastspec = data_train['CONTINUUM_AV_FASTSPEC'][snr_cut][:n_train]\n",
    "\n",
    "#         coeffs_fastphot = data_train['CONTINUUM_COEFF_FASTPHOT'][snr_cut][:n_train]\n",
    "#         AV_fastphot = data_train['CONTINUUM_AV_FASTPHOT'][snr_cut][:n_train]\n",
    "\n",
    "#         line_ews = np.array(data_train[lines][snr_cut][:n_train])\n",
    "#         line_ivars = np.array(data_train[lines_ivar][snr_cut][:n_train])\n",
    "\n",
    "#         np.savez_compressed(server_paths[server]+\"target_selection/target_ids_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", target_ids)\n",
    "#         np.savez_compressed(server_paths[server]+\"target_selection/fiber_ids_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", fiber_ids)\n",
    "#         np.savez_compressed(server_paths[server]+\"target_selection/petal_locs_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", petal_locs)\n",
    "#         np.savez_compressed(server_paths[server]+\"target_selection/tile_ids_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", tile_ids)\n",
    "#         np.savez_compressed(server_paths[server]+\"target_selection/zs_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", zs)\n",
    "#         np.savez_compressed(server_paths[server]+\"target_selection/line_ews_selection\"+str(run)+\"_\" + str(lines[l]) + \".txt\", line_ews)\n",
    "#         np.savez_compressed(server_paths[server]+\"target_selection/line_ivars_selection\"+str(run)+\"_\" + str(lines[l]) + \".txt\", line_ivars)\n",
    "\n",
    "#         np.savez_compressed(server_paths[server]+\"target_selection/fastspec_coeffs_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", coeffs_fastspec)\n",
    "#         np.savez_compressed(server_paths[server]+\"target_selection/fastspec_AV_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", AV_fastspec)\n",
    "\n",
    "#         np.savez_compressed(server_paths[server]+\"target_selection/fastphot_coeffs_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", coeffs_fastphot)\n",
    "#         np.savez_compressed(server_paths[server]+\"target_selection/fastphot_AV_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", AV_fastphot)\n",
    "        \n",
    "#         # storing magnitudes to use in EW-from-ugriz-train-test\n",
    "#         mags = np.zeros([n_train, len(magnitude_names)])\n",
    "#         for i in range(len(magnitude_names)):\n",
    "#             mags[:,i] = data_train[magnitude_names[i]][snr_cut][:n_train]\n",
    "#             np.savez_compressed(server_paths[server]+\"target_selection/\" + magnitude_names[i] + \"_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt\", mags[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d333c9c5-2772-47f6-ac6b-3af721b443ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABSMAG_SDSS_U',\n",
       " 'ABSMAG_SDSS_G',\n",
       " 'ABSMAG_SDSS_R',\n",
       " 'ABSMAG_SDSS_I',\n",
       " 'ABSMAG_SDSS_Z',\n",
       " 'ABSMAG_W1']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "magnitude_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d252486a-f1a9-42c4-bf52-befe930bdfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "from astropy.visualization import *\n",
    "import mpl_scatter_density\n",
    "\n",
    "norm = ImageNormalize(vmin=0.01, vmax=40, stretch=PowerStretch(1.5))\n",
    "fig = plt.figure(1)\n",
    "ax = fig.add_subplot(1, 1, 1, projection='scatter_density')\n",
    "density=ax.scatter_density(line_ews[6], line_ews[8], cmap=plt.cm.jet,dpi=40,norm=norm)\n",
    "plt.xlim([0,25])\n",
    "plt.ylim([0,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7892d184-a050-4298-86f4-9f296e135dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeff18a-6d80-458e-9900-28258f7ee1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "[True]*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd871928-84ea-4897-b133-313ebab530ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
