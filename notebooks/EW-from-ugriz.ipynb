{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad63ce4a-bc9e-4295-83ee-5e1c703e947c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.table import Table,join\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import random\n",
    "from scipy import stats\n",
    "from sklearn.neighbors import KDTree\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from desitarget.targetmask import desi_mask, bgs_mask, mws_mask\n",
    "from LLR import LLR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import xgboost as xgb\n",
    "from LLR import LLR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "762dd977-d8d5-494d-9d5c-b894e5f0c6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: Cannot merge meta key 'EXTNAME' types <class 'str'> and <class 'str'>, choosing EXTNAME='FASTSPEC' [astropy.utils.metadata]\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'EXTNAME' types <class 'str'> and <class 'str'>, choosing EXTNAME='FASTPHOT' [astropy.utils.metadata]\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'CHECKSUM' types <class 'str'> and <class 'str'>, choosing CHECKSUM='caYXdTXWcYXWcYXW' [astropy.utils.metadata]\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATASUM' types <class 'str'> and <class 'str'>, choosing DATASUM='3872209941' [astropy.utils.metadata]\n",
      "/tmp/ipykernel_6800/4145400336.py:33: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  data.add_column(1/(data[\"OII_3726_EW_IVAR\"]+data[\"OII_3729_EW_IVAR\"]), name='OII_DOUBLET_EW_IVAR')\n"
     ]
    }
   ],
   "source": [
    "## DATA ##\n",
    "## I'm combining fastphot,fastspect, and ztile to make sure I use the same data everywhere ##\n",
    "\n",
    "zall_path = \"/global/cfs/cdirs/desi/spectro/redux/fuji/zcatalog/ztile-sv1-bright-cumulative.fits\"\n",
    "data1 = Table.read(zall_path,hdu=1)\n",
    "needed1 = [\"TARGETID\", \"SV1_BGS_TARGET\", \"SPECTYPE\", \"DELTACHI2\", \"Z\", \"ZWARN\", \"FIBER\", \"PETAL_LOC\", \"TILEID\"]\n",
    "\n",
    "fastspec_path = \"/global/cfs/cdirs/desi/spectro/fastspecfit/fuji/catalogs/fastspec-fuji-sv1-bright.fits\"\n",
    "data2 = Table.read(fastspec_path,hdu=1)\n",
    "data2.rename_column('CONTINUUM_COEFF', 'CONTINUUM_COEFF_FASTSPEC')\n",
    "data2.rename_column('CONTINUUM_AV', 'CONTINUUM_AV_FASTSPEC')\n",
    "\n",
    "needed2 = [\"TARGETID\", \"OII_3726_EW\", \"OII_3729_EW\", \"HGAMMA_EW\", \"HBETA_EW\", \"OIII_4959_EW\", \"OIII_5007_EW\", \"NII_6548_EW\", \"HALPHA_EW\", \"NII_6584_EW\", \"SII_6716_EW\", \"SII_6731_EW\",\\\n",
    "           \"FLUX_SYNTH_G\", \"FLUX_SYNTH_R\", \"FLUX_SYNTH_Z\", 'CONTINUUM_COEFF_FASTSPEC', 'CONTINUUM_AV_FASTSPEC',\\\n",
    "           \"OII_3726_EW_IVAR\", \"OII_3729_EW_IVAR\", \"HGAMMA_EW_IVAR\", \"HBETA_EW_IVAR\", \"OIII_4959_EW_IVAR\", \"OIII_5007_EW_IVAR\", \"NII_6548_EW_IVAR\", \"HALPHA_EW_IVAR\", \"NII_6584_EW_IVAR\",\\\n",
    "           \"SII_6716_EW_IVAR\", \"SII_6731_EW_IVAR\"]\n",
    "\n",
    "\n",
    "fastphot_path = \"/global/cfs/cdirs/desi/spectro/fastspecfit/fuji/catalogs/fastphot-fuji-sv1-bright.fits\"\n",
    "data3 = Table.read(fastphot_path,hdu=1)\n",
    "data3.rename_column('CONTINUUM_COEFF', 'CONTINUUM_COEFF_FASTPHOT')\n",
    "data3.rename_column('CONTINUUM_AV', 'CONTINUUM_AV_FASTPHOT')\n",
    "\n",
    "needed3 = [\"TARGETID\", \"ABSMAG_SDSS_U\", \"ABSMAG_SDSS_G\", \"ABSMAG_SDSS_R\", \"ABSMAG_SDSS_I\", \"ABSMAG_SDSS_Z\", \"ABSMAG_W1\", 'CONTINUUM_COEFF_FASTPHOT', 'CONTINUUM_AV_FASTPHOT']\n",
    "\n",
    "data4 = join(data1[needed1], data2[needed2], keys=\"TARGETID\")\n",
    "data = join(data4, data3[needed3], keys=\"TARGETID\")\n",
    "\n",
    "N=len(data['TARGETID'])\n",
    "\n",
    "## Adding the sum of OII doublets to use them as a single line\n",
    "data.add_column(data[\"OII_3726_EW\"]+data[\"OII_3729_EW\"], name='OII_DOUBLET_EW')\n",
    "data.add_column(1/(data[\"OII_3726_EW_IVAR\"]+data[\"OII_3729_EW_IVAR\"]), name='OII_DOUBLET_EW_IVAR')\n",
    "\n",
    "not_used, ind = np.unique(data['TARGETID'], return_index=True)\n",
    "data = data[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e6e3dfc-6f65-4a2b-a3e3-e6d1f19a1556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36223\n",
      "28520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6800/2986895657.py:41: RuntimeWarning: invalid value encountered in multiply\n",
      "  snr_all[:,0] = data_train[lines[0]]*np.sqrt(data_train[lines[0]+\"_IVAR\"])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 109>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    169\u001b[0m     kernel \u001b[38;5;241m=\u001b[39m DotProduct() \u001b[38;5;241m+\u001b[39m WhiteKernel()\n\u001b[1;32m    170\u001b[0m     gpr \u001b[38;5;241m=\u001b[39m GaussianProcessRegressor(kernel\u001b[38;5;241m=\u001b[39mkernel)\n\u001b[0;32m--> 171\u001b[0m     \u001b[43mgpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEW_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     EW_fit \u001b[38;5;241m=\u001b[39m gpr\u001b[38;5;241m.\u001b[39mpredict(x_valid)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# calculating spearman coefficient and nmad for fit.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/sklearn/gaussian_process/_gpr.py:272\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_marginal_likelihood(theta, clone_kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# First optimize starting from theta specified in kernel\u001b[39;00m\n\u001b[1;32m    270\u001b[0m optima \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    271\u001b[0m     (\n\u001b[0;32m--> 272\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constrained_optimization\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m            \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbounds\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m     )\n\u001b[1;32m    276\u001b[0m ]\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# Additional runs are performed from log-uniform chosen initial\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m# theta\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_restarts_optimizer \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/sklearn/gaussian_process/_gpr.py:603\u001b[0m, in \u001b[0;36mGaussianProcessRegressor._constrained_optimization\u001b[0;34m(self, obj_func, initial_theta, bounds)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constrained_optimization\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj_func, initial_theta, bounds):\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin_l_bfgs_b\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 603\u001b[0m         opt_res \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m            \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m            \u001b[49m\u001b[43minitial_theta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m         _check_optimize_result(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m\"\u001b[39m, opt_res)\n\u001b[1;32m    611\u001b[0m         theta_opt, func_min \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/scipy/optimize/_minimize.py:623\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    621\u001b[0m                               \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    627\u001b[0m                          \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/scipy/optimize/lbfgsb.py:360\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    354\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 360\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    363\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:267\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 267\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:233\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 233\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:134\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/scipy/optimize/optimize.py:74\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;124;03m\"\"\" returns the the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/scipy/optimize/optimize.py:68\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 68\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/sklearn/gaussian_process/_gpr.py:262\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit.<locals>.obj_func\u001b[0;34m(theta, eval_gradient)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(theta, eval_gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n\u001b[0;32m--> 262\u001b[0m         lml, grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_marginal_likelihood\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_gradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclone_kernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mlml, \u001b[38;5;241m-\u001b[39mgrad\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/sklearn/gaussian_process/_gpr.py:574\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.log_marginal_likelihood\u001b[0;34m(self, theta, eval_gradient, clone_kernel)\u001b[0m\n\u001b[1;32m    572\u001b[0m inner_term \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mik,jk->ijk\u001b[39m\u001b[38;5;124m\"\u001b[39m, alpha, alpha)\n\u001b[1;32m    573\u001b[0m \u001b[38;5;66;03m# compute K^-1 of shape (n_samples, n_samples)\u001b[39;00m\n\u001b[0;32m--> 574\u001b[0m K_inv \u001b[38;5;241m=\u001b[39m \u001b[43mcho_solve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGPR_CHOLESKY_LOWER\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    576\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;66;03m# create a new axis to use broadcasting between inner_term and\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;66;03m# K_inv\u001b[39;00m\n\u001b[1;32m    579\u001b[0m inner_term \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m K_inv[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, np\u001b[38;5;241m.\u001b[39mnewaxis]\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/scipy/linalg/decomp_cholesky.py:208\u001b[0m, in \u001b[0;36mcho_solve\u001b[0;34m(c_and_lower, b, overwrite_b, check_finite)\u001b[0m\n\u001b[1;32m    205\u001b[0m overwrite_b \u001b[38;5;241m=\u001b[39m overwrite_b \u001b[38;5;129;01mor\u001b[39;00m _datacopied(b1, b)\n\u001b[1;32m    207\u001b[0m potrs, \u001b[38;5;241m=\u001b[39m get_lapack_funcs((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpotrs\u001b[39m\u001b[38;5;124m'\u001b[39m,), (c, b1))\n\u001b[0;32m--> 208\u001b[0m x, info \u001b[38;5;241m=\u001b[39m \u001b[43mpotrs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_b\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_b\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124millegal value in \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124mth argument of internal potrs\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    211\u001b[0m                      \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m-\u001b[39minfo)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "server = 1 # 0 is perlmutter, 1 is cori\n",
    "server_paths = ['/pscratch/sd/a/ashodkh/', '/global/cscratch1/sd/ashodkh/']\n",
    "N=len(data['TARGETID'])\n",
    "\n",
    "## Selecting data and doing LLR to predict lines ##\n",
    "lines=[\"OII_DOUBLET_EW\",\"HGAMMA_EW\",\"HBETA_EW\",\"OIII_4959_EW\",\"OIII_5007_EW\",\"NII_6548_EW\",\"HALPHA_EW\"\\\n",
    "       ,\"NII_6584_EW\",\"SII_6716_EW\",\"SII_6731_EW\"]\n",
    "\n",
    "magnitude_names=[\"ABSMAG_SDSS_U\", \"ABSMAG_SDSS_G\", \"ABSMAG_SDSS_R\", \"ABSMAG_SDSS_I\", \"ABSMAG_SDSS_Z\"]\n",
    "#magnitude_names = ['FLUX_G', 'FLUX_R', 'FLUX_Z', 'FLUX_W1', 'FLUX_W2', 'Z']\n",
    " \n",
    "n=30*10**3 # initial selection size. Should be smaller later after selecting flux>0 from raw data to make sure same data is used.\n",
    " \n",
    "    \n",
    "# calculating min and max redshift to have de-redshifted wavelengths be in the interval w1,w2 A\n",
    "w1=3400\n",
    "w_min=3600\n",
    "z_min=w_min/w1-1\n",
    "w2 = 8500\n",
    "w_max = 9824\n",
    "z_max = 0.3\n",
    "\n",
    "\n",
    "## I need to mimick target-selection-only to get same data\n",
    "\n",
    "select = ((data[\"SV1_BGS_TARGET\"] & bgs_mask.mask(\"BGS_BRIGHT\"))>0)*(data[\"SPECTYPE\"]==\"GALAXY\")*(data[\"DELTACHI2\"]>=25)\\\n",
    "         *(data[\"Z\"]>z_min)*(data[\"Z\"]<z_max)*(data[\"ZWARN\"]==0)\n",
    "\n",
    "select_size = len(np.where(select)[0])\n",
    "print(select_size)\n",
    "data_select = data[select]\n",
    "#select_half = int(select_size/2)\n",
    "select_half = select_size - 1\n",
    "data_train = data_select[:select_half]\n",
    "data_test = data_select[select_half:]\n",
    "\n",
    "N = len(data_train['TARGETID'])\n",
    "snr_cut = 1\n",
    "# calculating snr for all lines and setting the snr cut boolean as select_snr\n",
    "snr_all = np.zeros([N,len(lines)])\n",
    "snr_all[:,0] = data_train[lines[0]]*np.sqrt(data_train[lines[0]+\"_IVAR\"])\n",
    "\n",
    "cut_Halpha = True # cut Halpha on all data and later cut snr>0 for every line separately\n",
    "cut_all = False # cut on all lines together, which extremely restricts the data\n",
    "for i in range(1,len(lines)):\n",
    "    snr_all[:,i]=data_train[lines[i]]*np.sqrt(data_train[lines[i]+\"_IVAR\"])\n",
    "    if cut_all:\n",
    "        select_snr = select_snr*(snr_all[:,i]>snr_cut)\n",
    "if cut_Halpha:\n",
    "    select_snr = snr_all[:,6]>snr_cut\n",
    "    \n",
    "#parameters\n",
    "l = 6\n",
    "N = 6\n",
    "run = 0\n",
    "loga = True     # if true then predicts log(EW)\n",
    "m = 6           # model index. 0 is LLR, 1 is RandomForest, 2 is GradientBoosting from sklearn, 3 is XGboost, 4 is neural network\n",
    "\n",
    "# adding snr cuts to target selection\n",
    "select = (select_snr)*(snr_all[:,l]>0)\n",
    "print(len(np.where(select)[0]))\n",
    "target_ids = data_train[\"TARGETID\"][select]\n",
    "target_ids2 = np.load(server_paths[server] + \"target_selection/target_ids_selection\" + str(run) + \"_\" + str(lines[l]) + \".txt.npz\")['arr_0']\n",
    "\n",
    "target_pos = np.where(select)[0][:n] \n",
    "\n",
    "# flux cut after initial target selection and taking first n data\n",
    "n = 23*10**3\n",
    "target_pos = target_pos[:n]\n",
    "\n",
    "# assigning features as colors and standardizing them. I also add ones to include the y-intercept as part of the parameter matrix if m==0 (LLR).\n",
    "magnitudes_s = data_train[magnitude_names][target_pos]  \n",
    "magnitudes = np.zeros([n,len(magnitude_names)])\n",
    "for j in range(len(magnitude_names)):\n",
    "    magnitudes[:,j] = magnitudes_s[magnitude_names[j]][:n]\n",
    "\n",
    "ones = np.ones([n,1])\n",
    "scalar = StandardScaler()\n",
    "x = np.zeros([n,len(magnitude_names)-1])\n",
    "for i in range(n):\n",
    "    if target_ids[i] != target_ids2[i]:\n",
    "        raise ValueError('target_ids dont match')\n",
    "    for j in range(len(magnitude_names)-1):\n",
    "        x[i,j] = magnitudes[i,j]-magnitudes[i,j+1]\n",
    "x = scalar.fit_transform(x)\n",
    "\n",
    "if m == 0 or m == 5:\n",
    "    x = np.concatenate((ones,x),axis=1)\n",
    "\n",
    "# assigning outcomes as EW (equivalent width) and getting their inverse variance\n",
    "if loga:\n",
    "    EW = np.log10(data_train[lines[l]][target_pos])\n",
    "else:\n",
    "    EW = data_train[lines[l]][target_pos]\n",
    "ivar=data_train[lines[l]+\"_IVAR\"][target_pos]\n",
    "\n",
    "## doing cross-validation by splitting data into N_cv intervals. I store all the outcomes in EW_fit_all, ivar_all, etc...\n",
    "N_cv = 10\n",
    "x_split = np.split(x,N_cv)\n",
    "EW_split = np.split(EW,N_cv)\n",
    "ivar_split = np.split(ivar,N_cv)\n",
    "\n",
    "EW_fit_all = []\n",
    "EW_obs_all = []\n",
    "ivar_all = []\n",
    "\n",
    "spearman_all = []\n",
    "nmad_all = []\n",
    "for i in range(N_cv):\n",
    "    ## assigning the training and validation sets\n",
    "    x_valid = x_split[i]\n",
    "    EW_valid = EW_split[i]\n",
    "    ivar_valid = ivar_split[i]\n",
    "    x_to_combine = []\n",
    "    EW_to_combine = []\n",
    "    for j in range(N_cv):\n",
    "        if j != i:\n",
    "            x_to_combine.append(x_split[j])\n",
    "            EW_to_combine.append(EW_split[j])\n",
    "    x_train = np.concatenate(tuple(x_to_combine),axis=0)\n",
    "    EW_train = np.concatenate(tuple(EW_to_combine),axis=0)\n",
    "\n",
    "    # predicting EWs using LLR\n",
    "    if m == 0:\n",
    "        EW_fit,zeros = LLR.LLR(x_valid, x_train, EW_train, 100, 'inverse_distance')\n",
    "        EW_valid = np.delete(EW_valid, zeros, axis=0)\n",
    "        ivar_valid = np.delete(ivar_valid, zeros, axis=0)\n",
    "    if m == 1:\n",
    "        model = RandomForestRegressor(n_estimators=100)\n",
    "        model.fit(x_train, EW_train)\n",
    "        EW_fit = model.predict(x_valid)\n",
    "    if m == 2:\n",
    "        model = GradientBoostingRegressor(n_estimators=100)\n",
    "        model.fit(x_train, EW_train)\n",
    "        EW_fit = model.predict(x_valid)\n",
    "    if m == 3:\n",
    "        model = xgb.XGBRegressor(n_estimators=1000, learning_rate=0.05)\n",
    "        model.fit(x_train, EW_train, early_stopping_rounds=5, eval_set=[(x_valid,EW_valid)], verbose=False)\n",
    "        EW_fit = model.predict(x_valid)\n",
    "        print(model.best_ntree_limit)\n",
    "    if m == 4:\n",
    "        model_input = layers.Input(shape=x.shape[1])\n",
    "        h1 = layers.Dense(units=150, kernel_initializer=\"he_normal\")(model_input)\n",
    "        a1 = layers.PReLU()(h1)\n",
    "        h2 = layers.Dense(units=150, kernel_initializer=\"he_normal\")(a1)\n",
    "        a2 = layers.PReLU()(h2)\n",
    "        h3 = layers.Dense(units=150, kernel_initializer=\"he_normal\")(a2)\n",
    "        a3 = layers.PReLU()(h3)\n",
    "        output_layer = layers.Dense(1, activation='linear')(a3)\n",
    "        model = keras.models.Model(inputs=model_input, outputs=output_layer)\n",
    "        # model=keras.Sequential([\n",
    "        #     layers.Dense(units=100, kernel_initializer=\"he_normal\", activation='PReLU', input_shape=[x.shape[1]]),\n",
    "        #     layers.Dense(units=100, kernel_initializer=\"he_normal\", activation='PReLU'),\n",
    "        #     layers.Dense(units=100, kernel_initializer=\"he_normal\", activation='PReLU'),\n",
    "        #     layers.Dense(units=1, activation=\"linear\"),\n",
    "        # ])\n",
    "        model.compile(optimizer='Adam', loss='mse', metrics='mse')\n",
    "        n_epochs = 100\n",
    "        batch_size = 100\n",
    "        history = model.fit(x_train, EW_train, batch_size=batch_size, epochs=n_epochs, verbose=0, validation_data=(x_valid, EW_valid))\n",
    "        EW_fit = model.predict(x_valid)\n",
    "\n",
    "    if m == 5:\n",
    "        EW_fit,zeros = LLR.LLR_slow(x_valid, x_train, EW_train, 800, 'inverse_distance')\n",
    "        EW_valid = np.delete(EW_valid, zeros, axis=0)\n",
    "        ivar_valid = np.delete(ivar_valid, zeros, axis=0)\n",
    "\n",
    "    if m ==6:\n",
    "        kernel = RBF()\n",
    "        gpr = GaussianProcessRegressor(kernel=kernel)\n",
    "        gpr.fit(x_train, EW_train)\n",
    "        EW_fit = gpr.predict(x_valid)\n",
    "\n",
    "    # calculating spearman coefficient and nmad for fit.\n",
    "    nmad = np.abs(EW_fit-EW_valid)\n",
    "\n",
    "    EW_fit_all.append(EW_fit)\n",
    "    EW_obs_all.append(EW_valid)\n",
    "    ivar_all.append(ivar_valid)\n",
    "\n",
    "    spearman_all.append(stats.spearmanr(EW_fit,EW_valid)[0])\n",
    "    nmad_all.append(1.48*np.median(nmad))\n",
    "\n",
    "print(lines[l])\n",
    "print(spearman_all)\n",
    "print(\"av spearman = \"+str(np.average(spearman_all)))\n",
    "print(nmad_all)\n",
    "print(\"av nmad = \"+str(np.average(nmad_all)))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# if loga:\n",
    "#     np.savez_compressed(server_paths[server] + \"ew_results/ugriz/m\" +str(m)+ \"/logEW_fit_ugriz_selection\"+str(run)+\"_line\"+str(lines[l])+\"_bins\"+str(N)\\\n",
    "#                             +\"_ML\"+str(m)+\".txt\", EW_fit_all)\n",
    "#     np.savez_compressed(server_paths[server] + \"ew_results/ugriz/m\" +str(m)+ \"/logEW_obs_ugriz_selection\"+str(run)+\"_line\"+str(lines[l])+\"_bins\"+str(N)\\\n",
    "#                             +\"_ML\"+str(m)+\".txt\", EW_obs_all)\n",
    "#     np.savez_compressed(server_paths[server] + \"ew_results/ugriz/m\" +str(m)+ \"/line_ivars_ugriz_selection\"+str(run)+\"_line\"+str(lines[l])+\"_bins\"+str(N)\\\n",
    "#                             +\"_ML\"+str(m)+\".txt\", ivar_all)\n",
    "    # else:\n",
    "    #     np.savez_compressed(server_paths[server] + \"results/EW_fit_classical_selection\"+str(run)+\"_line\"+str(lines[l])+\"_bins\"+str(N)+\"_model\"+str(m)+\".txt\",EW_fit_all)\n",
    "    #     np.savez_compressed(server_paths[server] + \"results/EW_obs_classical_selection\"+str(run)+\"_line\"+str(lines[l])+\"_bins\"+str(N)+\"_model\"+str(m)+\".txt\",EW_obs_all)\n",
    "    #     np.savez_compressed(server_paths[server] + \"results/EW_ivar_classical_selection\"+str(run)+\"_line\"+str(lines[l])+\"_bins\"+str(N)+\"_model\"+str(m)+\".txt\",ivar_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d26af7e-ce7f-4639-9ac8-3a8325081d5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mEW_fit_all\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "EW_fit_all[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd6c09e4-6e8d-4c57-b0d1-1ce9a86c3e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8459659753644809"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearman_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeca8f74-1601-4165-9d8c-0570a2c68f84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
